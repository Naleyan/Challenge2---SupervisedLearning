{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4d6d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow # pour ceux qui l'ont pas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411ee843",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import SVC\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42b946e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = pd.read_csv(\"tracks.tsv\", sep=\"\\t\", dtype={\"track_id\": str})\n",
    "echonest = pd.read_csv(\"echonest_features.tsv\", sep=\"\\t\", dtype={\"track_id\": str})\n",
    "spectral = pd.read_csv(\"spectral_features.tsv\", sep=\"\\t\", dtype={\"track_id\": str})\n",
    "genres = pd.read_csv(\"genres.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f91f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tracks_columns : Index(['track_id', 'album_title', 'album_tracks', 'artist_latitude',\n",
      "       'artist_longitude', 'artist_name', 'duration', 'favorites', 'genre_top',\n",
      "       'genres', 'genres_all', 'interest', 'listens', 'title'],\n",
      "      dtype='object')\n",
      "echonest_columns : Index(['track_id', 'acousticness', 'danceability', 'energy',\n",
      "       'instrumentalness', 'liveness', 'speechiness', 'tempo', 'valence'],\n",
      "      dtype='object')\n",
      "spectral_columns : Index(['track_id', 'spectral_bandwidth_kurtosis_01',\n",
      "       'spectral_bandwidth_max_01', 'spectral_bandwidth_mean_01',\n",
      "       'spectral_bandwidth_median_01', 'spectral_bandwidth_min_01',\n",
      "       'spectral_bandwidth_skew_01', 'spectral_bandwidth_std_01',\n",
      "       'spectral_centroid_kurtosis_01', 'spectral_centroid_max_01',\n",
      "       'spectral_centroid_mean_01', 'spectral_centroid_median_01',\n",
      "       'spectral_centroid_min_01', 'spectral_centroid_skew_01',\n",
      "       'spectral_centroid_std_01', 'spectral_rolloff_kurtosis_01',\n",
      "       'spectral_rolloff_max_01', 'spectral_rolloff_mean_01',\n",
      "       'spectral_rolloff_median_01', 'spectral_rolloff_min_01',\n",
      "       'spectral_rolloff_skew_01', 'spectral_rolloff_std_01'],\n",
      "      dtype='object')\n",
      "genres_columns : Index(['genre_id', 'genre_color', 'genre_handle', 'genre_parent_id',\n",
      "       'genre_title'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"tracks_columns :\", tracks.columns)\n",
    "print(\"echonest_columns :\", echonest.columns)\n",
    "print(\"spectral_columns :\", spectral.columns)   \n",
    "print(\"genres_columns :\", genres.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66252c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_cols(df):\n",
    "    df.columns = (df.columns\n",
    "                    .str.lower()\n",
    "                    .str.strip()\n",
    "                    .str.replace(\" \", \"_\")\n",
    "                    .str.replace(\"-\", \"_\")\n",
    "                    .str.replace(r\"[^a-zA-Z0-9_]\", \"\", regex=True))\n",
    "    return df\n",
    "        \n",
    "tracks = clean_cols(tracks)\n",
    "echonest = clean_cols(echonest)\n",
    "spectral = clean_cols(spectral)\n",
    "genres = clean_cols(genres)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0895568b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tracks.merge(echonest, on=\"track_id\", how=\"left\") \\\n",
    "           .merge(spectral, on=\"track_id\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d29a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"tracks_merged.csv\", index=False) # Les 3 fichiers merged "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd75e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Création de colonnes pour les genres\n",
    "\n",
    "genres_df = pd.read_csv(\"genres.csv\")\n",
    "\n",
    "genres_df = genres_df.rename(columns={\n",
    "    \"genre_id\": \"id\",\n",
    "    \"genre_title\": \"name\"\n",
    "})\n",
    "\n",
    "# dictionnaire : id -> nom\n",
    "id_to_name = dict(zip(genres_df[\"id\"], genres_df[\"name\"]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce5608c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df.loc[0, \"genres\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d5f4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"genres\"] = df[\"genres\"].apply(ast.literal_eval)\n",
    "df[\"genres_all\"] = df[\"genres_all\"].apply(ast.literal_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "817b85c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ids_to_names(id_list):\n",
    "    return [id_to_name.get(i, \"UNKNOWN\") for i in id_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bc966ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"genres_names\"] = df[\"genres\"].apply(ids_to_names)\n",
    "df[\"genres_all_names\"] = df[\"genres_all\"].apply(ids_to_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "afd0fbc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genre_top</th>\n",
       "      <th>genres_names</th>\n",
       "      <th>genres_all_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>[Hip-Hop]</td>\n",
       "      <td>[Hip-Hop]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>[Hip-Hop]</td>\n",
       "      <td>[Hip-Hop]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>[Hip-Hop]</td>\n",
       "      <td>[Hip-Hop]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>[Hip-Hop]</td>\n",
       "      <td>[Hip-Hop]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>[Hip-Hop]</td>\n",
       "      <td>[Hip-Hop]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  genre_top genres_names genres_all_names\n",
       "0   Hip-Hop    [Hip-Hop]        [Hip-Hop]\n",
       "1   Hip-Hop    [Hip-Hop]        [Hip-Hop]\n",
       "2   Hip-Hop    [Hip-Hop]        [Hip-Hop]\n",
       "3   Hip-Hop    [Hip-Hop]        [Hip-Hop]\n",
       "4   Hip-Hop    [Hip-Hop]        [Hip-Hop]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"genre_top\", \"genres_names\", \"genres_all_names\"]].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c340f9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"genres_named.csv\", index=False) #merge de df mais avec les noms de genre"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc691a7b",
   "metadata": {},
   "source": [
    "# Task 1 - Predict the original genre\n",
    "## A multi-class classification problem. Try to reach the best performance level and also explain possible issue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72373a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = LabelEncoder().fit_transform(df[\"genre_top\"])\n",
    "X = df.drop(columns=[\"genre_top\", \"track_id\"])\n",
    "X = X.select_dtypes(include=[np.number]) #include=[\"number\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "\"\"\"\n",
    "On peut utiliser:\n",
    "Logistic Regression (multi-class)\n",
    "Random Forest\n",
    "Gradient Boosting\n",
    "XGBoost / LightGBM\n",
    "SVM\n",
    "kNN\n",
    "Decision trees\n",
    "Neural Network\n",
    "Deep Learning\n",
    "\"\"\"\n",
    "# Logistic Regression\n",
    "model = LogisticRegression(\n",
    "    multi_class=\"multinomial\",\n",
    "    solver=\"lbfgs\",\n",
    "    max_iter=1000,\n",
    "    class_weight=\"balanced\"   # utile si classes déséquilibrées\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=300,      # nombre d’arbres\n",
    "    max_depth=None,       # profondeur (None = libre)\n",
    "    random_state=42,\n",
    "    n_jobs=-1,            # utilise tous les cœurs\n",
    "    class_weight=\"balanced\"   # utile si classes déséquilibrées\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "importances = pd.Series(rf.feature_importances_, index=X.columns)\n",
    "print(importances.sort_values(ascending=False).head(20))\n",
    "\n",
    "# Grandient boosting\n",
    "gb = GradientBoostingClassifier(\n",
    "    n_estimators=200,    # nombre d’arbres\n",
    "    learning_rate=0.1,  # taux d’apprentissage\n",
    "    max_depth=3,        # profondeur des arbres de base\n",
    "    random_state=42\n",
    ")\n",
    "gb.fit(X_train, y_train)\n",
    "y_pred = gb.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# XGBoost\n",
    "xgb = XGBClassifier(\n",
    "    objective=\"multi:softmax\",     # multi-classes\n",
    "    num_class=len(set(y_train)),   # nombre de classes\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    eval_metric=\"mlogloss\",\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred = xgb.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "#LightGBM\n",
    "lgb = LGBMClassifier(\n",
    "    objective=\"multiclass\",\n",
    "    num_class=len(set(y_train)),\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=-1,\n",
    "    num_leaves=64,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=42\n",
    ")\n",
    "lgb.fit(X_train, y_train)\n",
    "y_pred = lgb.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# SVM\n",
    "svm = SVC(\n",
    "    kernel=\"rbf\",        # non linéaire, souvent le plus performant\n",
    "    C=1.0,               # régularisation\n",
    "    gamma=\"scale\",       # paramètre du noyau\n",
    "    class_weight=\"balanced\"\n",
    ")\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# kNN\n",
    "\n",
    "knn = KNeighborsClassifier(\n",
    "    n_neighbors=10,     # nombre de voisins\n",
    "    weights=\"distance\", # pondère les voisins proches\n",
    "    metric=\"minkowski\"  # distance euclidienne par défaut\n",
    ")\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "scores = []\n",
    "for k in [3, 5, 7, 10, 15, 20]:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k, weights=\"distance\")\n",
    "    knn.fit(X_train, y_train)\n",
    "    scores.append((k, accuracy_score(y_test, knn.predict(X_test))))\n",
    "\n",
    "print(scores)\n",
    "\n",
    "\n",
    "# Decision trees\n",
    "\n",
    "dt = DecisionTreeClassifier(\n",
    "    criterion=\"gini\",      # ou \"entropy\"\n",
    "    max_depth=None,        # ou un entier pour limiter la profondeur\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    class_weight=\"balanced\",   # utile si déséquilibre\n",
    "    random_state=42\n",
    ")\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "importances = pd.Series(dt.feature_importances_, index=X.columns)\n",
    "print(importances.sort_values(ascending=False).head(20))\n",
    "\n",
    "# Neural Network\n",
    "\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(128, 64),  # 2 couches cachées\n",
    "    activation=\"relu\",\n",
    "    solver=\"adam\",\n",
    "    batch_size=64,\n",
    "    max_iter=300,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "mlp.fit(X_train, y_train) #X_train_std\n",
    "y_pred = mlp.predict(X_test) #X_test_std\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Deep Learning\n",
    "n_features = X_train.shape[1] #X_train_std\n",
    "n_classes = len(np.unique(y_train))\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(n_features,)),\n",
    "    layers.Dense(256, activation=\"relu\"),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(n_classes, activation=\"softmax\")\n",
    "])\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=10,\n",
    "    restore_best_weights=True,\n",
    "    monitor=\"val_loss\"\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train, #X_train_std\n",
    "    validation_split=0.2,   # 20% du train utilisé pour la validation\n",
    "    epochs=100,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test) #X_test_std\n",
    "print(\"Test accuracy (deep learning):\", test_acc)\n",
    "\n",
    "y_proba = model.predict(X_test) #X_test_std\n",
    "y_pred = y_proba.argmax(axis=1)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": "mon_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
